{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ee962b2-38f0-49ea-ae18-fd52081b6820",
   "metadata": {},
   "source": [
    "Image registration tool using cv2  \n",
    "\n",
    "Possible future features:\n",
    "* Preprocess image if needed (e.g. invert pixel value)\n",
    "* change sift parameters\n",
    "* Iterating over Lowe's Ratio Test - Maybe values between 0.6-0.8 - lower is more selective.\n",
    "* Change RANSAC reprojection threshold - a smaller value will increase precision (fewer incorrect matches will be accepted), but may also decrease recall (fewer total matches will be found).\n",
    "* Use both mean distance and num_inliers to calculate quality (currently only mean_distance is used)\n",
    "* Maybe change the random seed to get better registration results (and loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12e8452a-9a50-4b71-bdba-1a7c8bcdf4fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "try: \n",
    "    import aicspylibczi\n",
    "except ImportError:\n",
    "    logging.warning(\"CZI can't be read, as aicspylibczi is not installed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "822e05d4-3658-4d07-8373-88f6801e87fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:test\n"
     ]
    }
   ],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logging.info(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ca0c5d5-3988-4b30-a694-2fefd5552133",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_czi_image(czi, channel=0):\n",
    "    ## need to have scale_factor as parameter - scale_factor=0.25\n",
    "    full_channel = czi.read_mosaic(C=1)[0]\n",
    "    return full_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "086e0249-04bf-4a1b-954f-e8b0ad4f5177",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_czi(image_path):\n",
    "    czi = aicspylibczi.CziFile(image_path)\n",
    "    print_czi_metadata(czi)\n",
    "    image = read_czi_image(czi)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3f1046c-b839-4403-a424-bbea43a5523b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_czi_metadata(czi):\n",
    "    logging.info('CZI metadata:')\n",
    "    logging.info(czi.dims)\n",
    "    logging.info(czi.size)\n",
    "    logging.info(czi.get_dims_shape())\n",
    "    logging.info(czi.is_mosaic())\n",
    "    # for i in czi.meta.iter():\n",
    "    #     logging.info(i, i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "650c1134-a781-47a7-ba78-113e405091ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_image(image_path):\n",
    "    if os.path.splitext(image_path)[-1] == '.czi':\n",
    "        image = read_czi(image_path)\n",
    "    else:\n",
    "        image = cv2.imread(image_path)\n",
    "        \n",
    "    logging.info(f'{image_path} image shape: {image.shape}')\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e5401ea-6b22-4774-b285-d7a7ec5f9693",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_image_mid_part(image):\n",
    "    \n",
    "    height = min(image.shape[0], 1000)\n",
    "    width = min(image.shape[1], 1000)\n",
    "    \n",
    "    image = image[image.shape[0]//2-height//2:image.shape[0]//2+height//2,\n",
    "                  image.shape[1]//2-width//2:image.shape[1]//2+width//2]\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "314f8e28-b4bd-49e6-b8cb-e86b4c33b2f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def log_image_metadata(image, is_preprocessed=True):\n",
    "    \n",
    "    processed_str = ' after preprocessing' if is_preprocessed else ''\n",
    "    \n",
    "    logging.info(f'image shape{processed_str}: {image.shape}')\n",
    "    logging.info(f'image dtype{processed_str}: {image.dtype}')\n",
    "    logging.info(f'image range{processed_str}: {np.min(image), np.max(image)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bacdf479-be73-4c4b-a720-16df9924ecbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "            \n",
    "    if image.ndim==3:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "    image = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX).astype('uint8')\n",
    "    #image = cv2.equalizeHist(image)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4c608b9-3acb-4e8b-adef-e021ccab060b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_and_preprocess_images(source_image_path, destination_image_path, is_preprocess=True):\n",
    "    \n",
    "    src_img = read_image(source_image_path)\n",
    "    dst_img = read_image(destination_image_path)\n",
    "    \n",
    "    log_image_metadata(image, is_preprocessed=False)\n",
    "    \n",
    "    if is_preprocess:\n",
    "        src_img = preprocess_image(src_img)\n",
    "        dst_img = preprocess_image(dst_img)\n",
    "        log_image_metadata(image)\n",
    "    \n",
    "    return src_img, dst_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec934220-509b-44f8-a04a-9628e9e681db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def def_flann_matches():\n",
    "    # Use FLANN (Fast Library for Approximate Nearest Neighbors) to find matches\n",
    "    FLANN_INDEX_KDTREE = 1\n",
    "    index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "    search_params = dict(checks=50)\n",
    "\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    \n",
    "    return flann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a526f8ca-1467-4a85-b7ac-b9aa9f5e738c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def def_bf_matcher():\n",
    "#     bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "#     return bf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e367825-55d3-46f2-91ca-37e8450cf430",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## might want to iterate over the Lowe's ratio for better registration results\n",
    "def get_good_matches(matches):\n",
    "    # Store all the good matches using Lowe's ratio test\n",
    "    good_matches = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.8 * n.distance:\n",
    "            good_matches.append(m)\n",
    "            \n",
    "    return good_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8900c0e1-be1f-4799-a780-85ecd1125f66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_pts_from_matches(good_matches, kp1, kp2):\n",
    "    if len(good_matches) > 10:\n",
    "        src_pts = np.float32([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "        dst_pts = np.float32([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "    else:\n",
    "        raise AssertionError(\"Not enough matches found for image registration.\")\n",
    "        \n",
    "    return src_pts, dst_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dfbf0a-6874-4f40-b351-b1d6ff04e81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_good_matches(src_img, dst_img, src_pts, dst_pts):\n",
    "    fig, ax = plt.subplots(1,2,figsize=(20,10))\n",
    "    \n",
    "    ax[0].imshow(src_img)\n",
    "    ax[0].axis('off')\n",
    "    ax[0].plot(*src_pts.T, marker='v', color=\"red\")\n",
    "    for i,loc in enumerate(src_pts):\n",
    "        ax[0].annotate(i, *loc)\n",
    "        \n",
    "    ax[1].imshow(dst_img)\n",
    "    ax[1].axis('off')\n",
    "    ax[1].plot(*dst_pts.T, marker='v', color=\"red\")\n",
    "    for i,loc in enumerate(dst_pts):\n",
    "        ax[1].annotate(i, *loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c27ca65-0d2e-432f-b251-cd57a150eb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_registration_by_kpts_mean_sqrt(src_pts, dst_pts, H, mask):\n",
    "    \n",
    "    # Map the keypoints in the source image to the destination image using the homography\n",
    "    mapped_src_pts = cv2.perspectiveTransform(src_pts, H)\n",
    "\n",
    "    # Calculate the Euclidean distances between the mapped source keypoints and the destination keypoints\n",
    "    distances = np.sqrt(np.sum((mapped_src_pts - dst_pts)**2, axis=2))\n",
    "    \n",
    "    inlier_distances = distances[mask == 1]\n",
    "\n",
    "    # Calculate the mean of the distances\n",
    "    mean_distance = np.mean(inlier_distances)\n",
    "\n",
    "    logging.info(f'Mean Euclidean distance between mapped source keypoints and destination keypoints: {mean_distance}')\n",
    "    \n",
    "    return mean_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d85d3d8-995c-4694-8064-805df5f91a1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_registration_by_num_inliers(mask):\n",
    "    \n",
    "    # Convert mask to a list\n",
    "    mask = mask.ravel().tolist()\n",
    "    \n",
    "    # Count the number of inliers and outliers\n",
    "    num_inliers = mask.count(1)\n",
    "    num_outliers = mask.count(0)\n",
    "\n",
    "    logging.info(f'RANSAC number of Inliers: {num_inliers}')\n",
    "    logging.info(f'RANSAC number of Outliers: {num_outliers}')\n",
    "    \n",
    "    return num_inliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f0df87-daef-47fa-9607-c9876272e1b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_degenerate(points):\n",
    "    # Compute the standard deviation of the points\n",
    "    std_dev = np.std(points, axis=0)\n",
    "\n",
    "    # If the standard deviation is below a threshold (here 1.0), \n",
    "    # it might indicate that the points are in a degenerate configuration.\n",
    "    if np.any(std_dev < 1.0):\n",
    "        print(\"Warning: points may be in a degenerate configuration.\")\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aeecb45-b503-4f73-838c-f613af03b753",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_transformation_quality(H, src_img):\n",
    "    # Create a grid of points in the source image\n",
    "    height, width = src_img.shape[:2]\n",
    "    x = np.linspace(0, width, num=50)\n",
    "    y = np.linspace(0, height, num=50)\n",
    "    xv, yv = np.meshgrid(x, y)\n",
    "    points = np.column_stack([xv.ravel(), yv.ravel()])\n",
    "\n",
    "    # Transform the points using the homography\n",
    "    points_t = cv2.perspectiveTransform(points.reshape(-1, 1, 2), H)\n",
    "\n",
    "    # Compute the standard deviation of the transformed points\n",
    "    std_dev = np.std(points_t, axis=0)\n",
    "\n",
    "    # If the standard deviation is very small or very large, it might indicate a poor transformation.\n",
    "    if np.any(std_dev < 1.0) or np.any(std_dev > max(height, width)):\n",
    "        print(\"Warning: transformation may be poor.\")\n",
    "        return False\n",
    "\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6145ee-ae84-4216-9c2e-c92f5a130ae3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_registration(src_pts, dst_pts, H, mask):\n",
    "    mean_distance = test_registration_by_kpts_mean_sqrt(src_pts, dst_pts, H, mask)\n",
    "    num_inliers = test_registration_by_num_inliers(mask)\n",
    "    \n",
    "    return mean_distance, num_inliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d475d4-ca20-4508-95f3-79678c163b3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_sift_based_registration_matrix(src_img, dst_img):\n",
    "    \n",
    "    # Find keypoints and descriptors for the images\n",
    "    kp1, des1 = sift.detectAndCompute(src_img, None)\n",
    "    kp2, des2 = sift.detectAndCompute(dst_img, None)\n",
    "    \n",
    "    matches = flann.knnMatch(des1, des2, k=2)\n",
    "    # good_matches = bf.match(des1, des2)\n",
    "    # good_matches = sorted(good_matches, key = lambda x:x.distance)\n",
    "\n",
    "    #### THIS SEEMS TO BE THE LINE WITH THE INCONSISTANCY BETWEEN RUNS!!!!!!\n",
    "    good_matches = get_good_matches(matches)\n",
    "    \n",
    "    src_pts, dst_pts = get_pts_from_matches(good_matches, kp1, kp2)\n",
    "    #plot_good_matches(src_img, dst_img, src_pts, dst_pts)\n",
    "    \n",
    "    # Call the function before computing homography\n",
    "    if check_degenerate(src_pts) or check_degenerate(dst_pts):\n",
    "        print(\"Degenerate configuration detected, handling this case separately...\")\n",
    "        # Add your handling code here\n",
    "        \n",
    "    H, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5)\n",
    "    \n",
    "    mean_distance, num_inliers = test_registration(src_pts, dst_pts, H, mask)\n",
    "    check_transformation_quality(H, src_img)\n",
    "    \n",
    "    return H, mean_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d5d9c4-adb6-4fd0-a381-a07c2583938a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def warp_image(dst_img, src_img, H):\n",
    "    # Warp the source image using the homography matrix\n",
    "    #height, width, _ = dst_img.shape\n",
    "    height, width = dst_img.shape\n",
    "    registered_img = cv2.warpPerspective(src_img, H, (width, height))\n",
    "    \n",
    "    return registered_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a46df38-29d2-4c1c-9a34-ed2f2eb62ebd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_results(output_path, h, registered_image):\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    cv2.imwrite(os.path.join(output_path, 'registered_image.png'), registered_image)\n",
    "    np.save(os.path.join(output_path, 'registration_matrix.npy'), h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36feba76-24d2-4e88-b423-932219253e06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_result(source_image, destination_image, registered_image):\n",
    "    fig, ax = plt.subplots(2,2,figsize=(20,20))\n",
    "    ax[0,0].imshow(source_image, cmap='gray')\n",
    "    ax[0,0].set_title('source image')\n",
    "    ax[0,0].axis('off')\n",
    "    ax[0,1].imshow(destination_image, cmap='gray')\n",
    "    ax[0,1].set_title('destination image')\n",
    "    ax[0,1].axis('off')\n",
    "    ax[1,0].imshow(registered_image, cmap='gray')\n",
    "    ax[1,0].set_title('registered image')\n",
    "    ax[1,0].axis('off')\n",
    "    ax[1,1].imshow(destination_image, cmap='gray')\n",
    "    ax[1,1].imshow(registered_image, alpha=0.3, cmap='hot_r')\n",
    "    ax[1,1].set_title('overlay')\n",
    "    ax[1,1].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff47a0e-d500-478d-a179-ab2734949436",
   "metadata": {},
   "outputs": [],
   "source": [
    "## add a function for scale factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c98935f-f55b-4a28-8206-82e47a036da6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    sift = cv2.SIFT_create()\n",
    "    # SIFT params: (int nfeatures=0, int nOctaveLayers=3, double contrastThreshold=0.04, double edgeThreshold=10, double sigma=1.6)\n",
    "    #3>nOctaveLayers>5\n",
    "    flann = def_flann_matches()\n",
    "    \n",
    "    # source_img_path = \"../akalin_assay_coregistration/data/morphology.png\"\n",
    "    # destination_img_path = \"../akalin_assay_coregistration/data/tissue_lowres_image.png\"\n",
    "    \n",
    "    source_img_path = '../burgstaller_channel_alignment/data/CPC_Pestoni_lung_24-01-2023_RUN1_slide0.czi'\n",
    "    destination_img_path = '../burgstaller_channel_alignment/data/CPC_Pestoni_RUN2_Slide0.czi'\n",
    "\n",
    "    output_path = \"registration_output\"\n",
    "\n",
    "    source_image, destination_image = read_and_preprocess_images(source_img_path, destination_img_path)\n",
    "    \n",
    "    # Try different rotations of the image:\n",
    "    lowest_mean_distance = np.inf\n",
    "\n",
    "    #for i in range(4):\n",
    "    for i in range(1):\n",
    "        cv2.setRNGSeed(0)\n",
    "        logging.info(f'Source image Rotated - {90*(i+1)%360}')\n",
    "        #source_image = cv2.rotate(source_image, cv2.ROTATE_90_CLOCKWISE)\n",
    "        h, mean_distance = get_sift_based_registration_matrix(source_image, destination_image)\n",
    "        if mean_distance<lowest_mean_distance:\n",
    "            lowest_mean_distance = mean_distance\n",
    "            H = h\n",
    "        logging.info('\\n')\n",
    "    \n",
    "    registered_image = warp_image(destination_image, source_image, H)\n",
    "    \n",
    "    save_results(output_path, h, registered_image)\n",
    "    plot_result(source_image, destination_image, registered_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e26507-9d85-4819-ad2a-60533409b72c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a scaling matrix\n",
    "scale = 0.25\n",
    "\n",
    "S = np.array([[scale, 0, 0], [0, scale, 0], [0, 0, 1]])\n",
    "\n",
    "# Adjust H\n",
    "H_full = np.dot(np.dot(np.linalg.inv(S), H), S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2167e13f-3feb-4401-9f90-27a7758efe93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "source_img_path = '../burgstaller_channel_alignment/data/CPC_Pestoni_lung_24-01-2023_RUN1_slide0.czi'\n",
    "destination_img_path = '../burgstaller_channel_alignment/data/CPC_Pestoni_RUN2_Slide0.czi'\n",
    "\n",
    "source_image, destination_image = read_and_preprocess_images(source_img_path, destination_img_path, is_preprocess=False)\n",
    "\n",
    "registered_image = warp_image(destination_image, source_image, H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1787727-26cc-4b04-a935-5474c1f66b1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_result(source_image, destination_image, registered_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33198e04-9fbd-489c-b289-2372ab6d6470",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,2,figsize=(20,20))\n",
    "ax[0,0].imshow(source_image, cmap='gray')\n",
    "ax[0,0].set_title('source image')\n",
    "ax[0,0].axis('off')\n",
    "ax[0,1].imshow(destination_image, cmap='gray')\n",
    "ax[0,1].set_title('destination image')\n",
    "ax[0,1].axis('off')\n",
    "ax[1,0].imshow(registered_image, cmap='gray')\n",
    "ax[1,0].set_title('registered image')\n",
    "ax[1,0].axis('off')\n",
    "ax[1,1].imshow(destination_image, cmap='gray')\n",
    "ax[1,1].imshow(source_image, alpha=0.3, cmap='hot_r')\n",
    "ax[1,1].set_title('overlay')\n",
    "ax[1,1].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8c4f66-5070-4e7a-9fd7-750714a99a80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
